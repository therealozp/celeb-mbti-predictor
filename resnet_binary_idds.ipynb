{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5af30017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c124a2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MBTI to index mapping: {'ENFJ': 1, 'ENFP': 1, 'ENTJ': 1, 'ENTP': 1, 'ESFJ': 1, 'ESFP': 1, 'ESTJ': 1, 'ESTP': 1, 'INFJ': 0, 'INFP': 0, 'INTJ': 0, 'INTP': 0, 'ISFJ': 0, 'ISFP': 0, 'ISTJ': 0, 'ISTP': 0}\n"
     ]
    }
   ],
   "source": [
    "from utils import assign_splits, get_label_mapping\n",
    "\n",
    "# assign_splits(\n",
    "#     file_path=\"faces_yolo_metadata.csv\",\n",
    "#     id_column=\"id\",\n",
    "#     label_column=\"mbti\",\n",
    "# )\n",
    "\n",
    "mbti_to_idx = get_label_mapping(\n",
    "    file_path=\"faces_yolo_id_split_metadata.csv\",\n",
    "    label_column=\"mbti\",\n",
    ")\n",
    "\n",
    "for key in mbti_to_idx:\n",
    "    if key.startswith(\"I\"):\n",
    "        mbti_to_idx[key] = 0\n",
    "    else: \n",
    "        mbti_to_idx[key] = 1\n",
    "\n",
    "print(\"MBTI to index mapping:\", mbti_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75a8c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "train_tf = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomApply([transforms.ColorJitter(0.25, 0.25, 0.25, 0.05)], p=0.8),\n",
    "        transforms.RandomApply(\n",
    "            [\n",
    "                transforms.RandomAffine(\n",
    "                    degrees=10,  # small rotation\n",
    "                    translate=(0.05, 0.05),  # small shifts\n",
    "                    scale=(0.9, 1.1),\n",
    "                )\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomErasing(\n",
    "            p=0.25, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=\"random\"\n",
    "        ),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_tf = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49a631df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9573 1201 1205\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from dataset import IDSplitCelebMBTIDataset\n",
    "\n",
    "train_ds = IDSplitCelebMBTIDataset(\n",
    "    root_dir=\"faces_yolo_id_split\",\n",
    "    metadata_csv=\"faces_yolo_id_split_metadata.csv\",\n",
    "    split=\"train\",\n",
    "    mbti_to_idx=mbti_to_idx,\n",
    "    transform=train_tf,\n",
    ")\n",
    "\n",
    "val_ds = IDSplitCelebMBTIDataset(\n",
    "    root_dir=\"faces_yolo_id_split\",\n",
    "    metadata_csv=\"faces_yolo_id_split_metadata.csv\",\n",
    "    mbti_to_idx=mbti_to_idx,\n",
    "    split=\"val\",\n",
    "    transform=val_tf,\n",
    ")\n",
    "\n",
    "test_ds = IDSplitCelebMBTIDataset(\n",
    "    root_dir=\"faces_yolo_id_split\",\n",
    "    metadata_csv=\"faces_yolo_id_split_metadata.csv\",\n",
    "    mbti_to_idx=mbti_to_idx,\n",
    "    split=\"test\",\n",
    "    transform=val_tf,\n",
    ")\n",
    "\n",
    "print(len(train_ds), len(val_ds), len(test_ds))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    print(images.shape)  # [Batch, 3, 224, 224]\n",
    "    print(labels.shape)  # [Batch, 4]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1eb7a1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import torch.nn as nn\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "in_features = model.fc.in_features\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(in_features, num_classes),\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da65401b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 00 [train]:  47%|████▋     | 142/300 [00:17<00:08, 19.27it/s, loss=0.722]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(50):\n",
    "    # training phase with tqdm\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch:02d} [train]\", leave=False)\n",
    "    model.train()\n",
    "    total_loss, total_correct, total = 0.0, 0, 0\n",
    "    for x, y in pbar:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "\n",
    "        # print(logits.shape, y.shape)  # Debugging line\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = logits.argmax(1)\n",
    "        total_correct += (preds == y).sum().item()\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        total += y.size(0)\n",
    "\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    tr_loss = total_loss / total\n",
    "    tr_acc = total_correct / total\n",
    "\n",
    "    # validation phase with tqdm\n",
    "    pbar = tqdm(val_loader, desc=f\"Epoch {epoch:02d} [val]\", leave=False)\n",
    "    model.eval()\n",
    "    total_loss, total_correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in pbar:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            preds = logits.argmax(1)\n",
    "            total_correct += (preds == y).sum().item()\n",
    "            total_loss += loss.item() * y.size(0)\n",
    "            total += y.size(0)\n",
    "\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    va_loss = total_loss / total\n",
    "    va_acc = total_correct / total\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | \"\n",
    "        f\"train loss {tr_loss:.4f}/ train accuracy {tr_acc:.3f} | \"\n",
    "        f\"val loss {va_loss:.4f}/ val accuracy {va_acc:.3f}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
